{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniższe ćwiczenie obrazuje użycie metod bagging i boosting do trenowania modeli uczenia maszynowego. Obie rodziny metod znane są pod nazwą klasyfikacji grupowej (ang. *ensemble methods*)\n",
    "\n",
    "  * **bagging**: polega na niezależnym wytrenowaniu zbioru słabych klasyfikatorów, których odpowiedzi są następnie uśredniane. Jeśli błędy popełniane przez klasyfikatory są od siebie niezależne, to użycie zbioru klasyfikatorów istotnie obniża prawdopodobieństwo popełnienia błędu przez większość\n",
    "  * **boosting**: polega na sukcesywnym trenowaniu kolejnych klasyfikatorów, każdy kolejny klasyfikator otrzymuje na wejście listę błędów popełnionych przez poprzedni klasyfikator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T23:19:12.153937Z",
     "start_time": "2020-06-10T23:19:11.626412Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T23:19:18.628313Z",
     "start_time": "2020-06-10T23:19:18.430474Z"
    }
   },
   "outputs": [],
   "source": [
    "# generowanie sztucznych danych\n",
    "\n",
    "generate = lambda x: x / 2 + (x // 10) % 2 * 20 * x / 5 + np.random.random() * 10\n",
    "\n",
    "X = np.arange(0, 60).reshape(-1,1)\n",
    "y = [generate(x)[0] for x in X]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(X, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pierwszym modelem jaki przetestujemy będzie najprostszy model liniowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T23:20:29.888271Z",
     "start_time": "2020-06-10T23:20:29.131973Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "linear_regressor = linear_model.LinearRegression()\n",
    "linear_regressor.fit(X,y)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Linear Regression\")\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X, linear_regressor.predict(X), color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Żeby zbadać jakość modelu narysujmy wartości resztowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T23:21:11.094438Z",
     "start_time": "2020-06-10T23:21:10.919327Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Residuals of Linear Regression model\")\n",
    "plt.scatter(X, y - linear_regressor.predict(X), color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spróbujemy poprawić powyższy model korzystając z techniki *boosting*. Zaczniemy od najprostszego modelu składającego się z jednego drzewa decyzyjnego o głębokości 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T23:22:07.126389Z",
     "start_time": "2020-06-10T23:22:07.056245Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "params = {\n",
    "    'n_estimators': 1,\n",
    "    'max_depth': 1,\n",
    "    'learning_rate': 1,\n",
    "    'criterion': 'squared_error'\n",
    "}\n",
    "\n",
    "gradient_boosting_regressor = ensemble.GradientBoostingRegressor(**params)\n",
    "gradient_boosting_regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T23:22:10.208436Z",
     "start_time": "2020-06-10T23:22:09.941845Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Gradient Boosting model (1 estimator, depth 1)')\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X, gradient_boosting_regressor.predict(X), color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeszcze raz spróbujmy obejrzeć wartości resztowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T23:22:47.675984Z",
     "start_time": "2020-06-10T23:22:47.413757Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Residuals of Gradient Boosting model (1 estimator, depth 1)\")\n",
    "plt.scatter(X, y - gradient_boosting_regressor.predict(X), color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T20:32:42.132440Z",
     "start_time": "2019-05-19T20:32:42.129394Z"
    }
   },
   "source": [
    "Jak widać, w przedziale [30,40] model popełnia bardzo duże błędy. Można im zapobiec dodając kolejny model do sekwencji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T23:23:20.411512Z",
     "start_time": "2020-06-10T23:23:20.403276Z"
    }
   },
   "outputs": [],
   "source": [
    "params['n_estimators'] = 2\n",
    "\n",
    "gradient_boosting_regressor = ensemble.GradientBoostingRegressor(**params)\n",
    "gradient_boosting_regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T23:23:21.536185Z",
     "start_time": "2020-06-10T23:23:21.364544Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Gradient Boosting model (2 estimators)')\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X, gradient_boosting_regressor.predict(X), color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać, drugie drzewa działa dla X=30 i generuje tam nową wartość. Możemy zatem spróbować dopasować wiele estymatorów w sekwencji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T23:24:10.341628Z",
     "start_time": "2020-06-10T23:24:09.509261Z"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "for idx, n_estimators in enumerate([5, 10, 20, 50]):\n",
    "    params['n_estimators'] = n_estimators\n",
    "\n",
    "    gradient_boosting_regressor = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "    gradient_boosting_regressor.fit(X, y)\n",
    "    subplot = ax[idx // 2][idx % 2]\n",
    "    subplot.set_title(f'Gradient Boosting model ({n_estimators} estimators)')\n",
    "    subplot.scatter(X, y)\n",
    "    subplot.plot(X, gradient_boosting_regressor.predict(X), color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zobaczmy, co się stanie, jeśli dla ustalonej liczby drzew pozwolimy indywidualnym drzewom znajdować więcej niż 1 punkt podziału"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T23:25:23.529156Z",
     "start_time": "2020-06-10T23:25:22.993195Z"
    }
   },
   "outputs": [],
   "source": [
    "params['n_estimators'] = 10\n",
    "\n",
    "f, ax = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "for idx, max_depth in enumerate([1, 2, 3, 5]):\n",
    "    params['max_depth'] = max_depth\n",
    "\n",
    "    gradient_boosting_regressor = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "    gradient_boosting_regressor.fit(X, y)\n",
    "    subplot = ax[idx // 2][idx % 2]\n",
    "    subplot.set_title(f'Gradient Boosting model ({max_depth} depth)')\n",
    "    subplot.scatter(X, y)\n",
    "    subplot.plot(X, gradient_boosting_regressor.predict(X), color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jako przykład metody *bagging* użyjemy najprostszej wersji metody, która buduje pewną liczbę modeli tego samego typu, za każdym razem używając próbki typu *bootstrap*, w której ze zbioru *n* elementów losujemy n-krotnie element ze zwracaniem. W uzyskanej w ten sposób próbce około $(1-\\frac{1}{e})=63.2\\%$ elementów jest unikalnych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T23:28:30.581868Z",
     "start_time": "2020-06-10T23:28:30.142694Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "params = {\n",
    "    'estimator': tree.DecisionTreeRegressor(),\n",
    "    'n_estimators': 100\n",
    "}\n",
    "\n",
    "bagging_regressor = ensemble.BaggingRegressor(**params)\n",
    "bagging_regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T23:28:33.713236Z",
     "start_time": "2020-06-10T23:28:33.431835Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Bagging Reggression model')\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X, bagging_regressor.predict(X), color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T23:29:20.371083Z",
     "start_time": "2020-06-10T23:29:20.146260Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Residuals of Bagging Regression model\")\n",
    "plt.scatter(X, y - bagging_regressor.predict(X), color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatywą dla takiego podejścia jest dobrze już znana technika losowych lasów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T23:30:29.894615Z",
     "start_time": "2020-06-10T23:30:29.776213Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': 5,\n",
    "    'n_estimators': 100,\n",
    "    'criterion': 'friedman_mse'\n",
    "}\n",
    "\n",
    "random_forest_regressor = ensemble.RandomForestRegressor(**params)\n",
    "random_forest_regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T23:30:31.192416Z",
     "start_time": "2020-06-10T23:30:31.017543Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Random Forest Reggression model')\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X, random_forest_regressor.predict(X), color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T23:30:50.706495Z",
     "start_time": "2020-06-10T23:30:50.532627Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Residuals of Random Forest Regression model\")\n",
    "plt.scatter(X, y - random_forest_regressor.predict(X), color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
